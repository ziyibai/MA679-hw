---
title: "SVM-hw"
author: "Ziyi Bai"
date: "2021/3/11"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(e1071)
library(ISLR)
```

## 9.3
##(a)
```{r}
x1 <- c(3,2,4,1,2,4,4)
x2 <- c(4,2,4,4,1,3,1)
cols <- c("red", "red", "red", "red", "blue", "blue", "blue")
plot(x1,x2,col=cols,xlim = c(0,5),ylim = c(0,5))
```
##(b)
```{r}
plot(x1,x2,col=cols,xlim = c(0,5),ylim = c(0,5))
abline(-0.5,1)
```
##(d)
```{r}
plot(x1,x2,col=cols,xlim = c(0,5),ylim = c(0,5))
abline(-0.5,1)
abline(-1,1,lty=2)
abline(0,1,lty=2)
```
##(e)
The support vectors for the maximal margin classifier are the points (2,1), (2,2), (4,3) and (4,4)

##(f)
The 7th observations is not a support vector, so move it won't affect the outcome.

##(g)
```{r}
plot(x1,x2,col=cols,xlim = c(0,5),ylim = c(0,5))
abline(-0.25,1)
```

## 9.5
##(a)
```{r}
set.seed(9)
x1=runif(500)-0.5
x2=runif(500)-0.5
y=1*(x1^2-x2^2 > 0)
```

##(b)
```{r}
plot(x1,x2,col=ifelse(y,"red","blue"))
```
##(c)
```{r}
df1 <- data.frame(x1,x2,y)
fit_glm <- glm(y~x1+x2, data=df1,family = binomial)
fit_glm
```
##(d)
```{r}
pred_fit <- predict(fit_glm,data.frame(x1,x2))
plot(x1,x2,col=ifelse(pred_fit>0,"red","blue"),pch=ifelse(as.integer(pred_fit>0)==y,1,4))
```
##(e)
```{r}
fit_glm1 <- glm(y~poly(x1,2)+poly(x2,2),data=df1,family = binomial)
summary(fit_glm1)

fit_glm2 <- glm(y~x1+x2+x1*x2,data=df1,family=binomial)
summary(fit_glm2)
```
##(f)
```{r}
pred_fit1 <- predict(fit_glm1, df1)
plot(x1, x2, col = ifelse(pred_fit1 > 0, "red", "blue"), pch = ifelse(as.integer(pred_fit1 > 0) == y, 1,4))
```
##(g)
```{r}
df1$y <- as.factor(df1$y)
fit_svc <- svm(y~x1+x2,data=df1,kernel="linear")
pred_svc <- predict(fit_svc,df1,type="response")
plot(x1,x2,col=ifelse(pred_svc!=0,"red","blue"),pch=ifelse(pred_svc==y,1,4))
```
##(h)
```{r}
fit_svm <- svm(y ~ x1 + x2, data = df1, kernel = "polynomial", degree = 2)
pred_svm <- predict(fit_svm, df1, type = "response")
plot(x1, x2, col = ifelse(pred_svm != 0, "red", "blue"), pch = ifelse(pred_svm == y, 1,4))
```
##(i)
Using polynomial gives us better result.

## 9.7
##(a)
```{r}
data("Auto")
Auto$Y <- ifelse(Auto$mpg > median(Auto$mpg),1,0)
Auto$Y <- as.factor(Auto$Y)
```
##(b)
```{r}
set.seed(9)
cost <- data.frame(cost=seq(0.01,100,length.out = 10))
svm_tune <- tune(svm,Y~.,data=Auto,kernel="linear",ranges = cost)
summary(svm_tune)
plot(svm_tune$performances[,c(1,2)],type="l")
```
cost=11.12 has the best performance.

##(c)
```{r}
para <- data.frame(cost=seq(0.01,100,length.out = 5),degree=seq(1,100,length.out = 5))
svm_poly <- tune(svm,Y~.,data=Auto,kernel="polynomial",ranges = para)
summary(svm_poly)
```
##(d)
```{r, fig.height=3, fig.width=4, fig.show='hold'}
linear <- svm(Y ~ ., data = Auto, kernel = "linear", cost = 11.12)
polynomial <- svm(Y ~ ., data = Auto, kernel = "polynomial", cost = 100, degree = 1)
radial <- svm(Y ~ ., data = Auto, kernel = "radial", cost = 25.0075, gamma = 0.1)
pair_plot <- function(a){
  for (name in names(Auto)[!(names(Auto) %in% c("mpg", "Y", "name"))])
    plot(a, Auto, as.formula(paste("mpg~", name, sep = "")))
}
pair_plot(linear)
```
```{r}
pair_plot(linear)
pair_plot(polynomial)
```
## 9.8
##(a)
```{r}
data("OJ")
set.seed(9)
train_oj <- sample(nrow(OJ),800)
oj_train <- OJ[train_oj,]
oj_test <- OJ[-train_oj,]
```

##(b)
```{r}
oj_svc <- svm(Purchase~., data=oj_train,kernel="linear",cost=0.01)
summary(oj_svc)
```

##(c)
```{r}
#Training error rate
pred_train <- predict(oj_svc, oj_train)
table(pred_train, oj_train$Purchase)
#Test error rate
pred_test <- predict(oj_svc, oj_test)
table(pred_test, oj_test$Purchase)
(tr_error<- (70+61)/(428+70+61+241))
(te_error <- (33+21)/(143+33+21+73))
```

##(d)
```{r}
oj_tune <- tune(svm, Purchase~.,data=oj_train,kernel="linear",ranges = data.frame(cost=seq(0.01,10,length.out = 25)))
summary(oj_tune)
```
The optimal cost is 3.75625.

##(e)
```{r}
#Training error rate
oj_svm <- svm(Purchase ~ ., data = oj_train, kernel = "linear", cost = oj_tune$best.parameters$cost)
svm_train <- predict(oj_svm, oj_train)
table(svm_train, oj_train$Purchase)
(tr_err <- (58+64)/(425+58+64+253))
#Test error rate
svm_test <- predict(oj_svm, oj_test)
table(svm_test, oj_test$Purchase)
(te_err <- (27+22)/(142+27+22+79))
```

##(f)
```{r}
## radial kernel
oj_radial <- svm(Purchase~., data = oj_train, kernel="radial")
summary(oj_radial)

## training error rate
radial_train <- predict(oj_radial,oj_train)
table(radial_train,oj_train$Purchase)
## test error rate
radial_test <- predict(oj_radial,oj_test)
table(radial_test,oj_test$Purchase)
#The training error rate is 14.5% and the test error rate is 18.89%.

## optimal cost
radial_tune <- tune(svm,Purchase~.,data=oj_train,kernel="radial",ranges = data.frame(cost=seq(0.01,10,length.out = 25)))
summary(radial_tune)

## training error rate
radial_svm <- svm(Purchase ~ ., data = oj_train, kernel = "radial", cost = radial_tune$best.parameters$cost)
svm_rad <- predict(radial_svm, oj_train)
table(svm_rad, oj_train$Purchase)
#Test error rate
svm_rad_test <- predict(radial_svm, oj_test)
table(svm_rad_test, oj_test$Purchase)
#The training error rate is 14.5% and the test error rate is 18.89%.
```

##(g)
```{r}
## polynomial kernel
oj_poly <- svm(Purchase~.,data=oj_train,kernel="polynomial",degree=2)
summary(oj_poly)
```

##(h)
linear kernel with cost of 3.75625 has the best result.















